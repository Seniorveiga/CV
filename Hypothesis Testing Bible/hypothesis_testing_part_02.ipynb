{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Hypothesis tests Part 2 Intro"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In this Notebook I will continue the **Hypothesis tests** main tests to clarify the difficulties while trying to understand this statistical concept. This is the second part of my series *\"The Hypothesis Testing Bible\"*. If you want to know further about the dataset or more elemental concepts, please check the first part on my GitHub repository. Link below.\n",
    "\n",
    "https://github.com/Seniorveiga/Python_Projects/tree/main/Hypothesis%20Testing%20Bible\n",
    "\n",
    "In this notebook we will have a walk over more complex tests. They will be:\n",
    "\n",
    "## Index\n",
    "\n",
    "- Proportion tests\n",
    "    - Tests for single and two proportions\n",
    "    - Proportions $\\mathit{z}$-test\n",
    "    - ${Chi^{2}}$ tests\n",
    "\n",
    "- Non-parametric tests\n",
    "    - Wilcoxon tests\n",
    "    - Wilcoxon-Man-Whotney tests\n",
    "    - Kruskal-Wallis tests"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Packages reminder\n",
    "\n",
    "To learn more about hypothesis tests, we will be working with two datasets, one that is called *late_shipments* and the other one called *republican_votes*. Right now we will be using only the first one in order to understand more about hypothesis tests.\n",
    "\n",
    "The *late_shipments* dataset contains supply chain data on the delivery of medical supplies. Each row represents one delivery of a part. \n",
    "- The **\"late\"** columns denotes whether or not the part was delivered late. A value of \"Yes\" means that the part was delivered late, and a value of \"No\" means the part was delivered on time.\n",
    "\n",
    "Also, for temporal comparing datasets we will use *repub_votes_potus_08_12* that has comparisons of the votes between republicans and democrats betweenn those years.\n",
    "\n",
    "- Since the counties are the same in both years, these samples are paired (Used in the paired t-test chapter). The columns containing the samples are *\"dem_percent_12\"* and *\"dem_percent_16\"*."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Packages and dataset import"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Again, we import the package so that it appears again to do our operations and the hypothesis tests."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import pyarrow.feather as feather\n",
    "import numpy as np \n",
    "from scipy.stats import norm, t\n",
    "import matplotlib.pyplot as plt\n",
    "import pingouin\n",
    "import seaborn as sns\n",
    "from statsmodels.stats.proportion import proportions_ztest\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>country</th>\n",
       "      <th>managed_by</th>\n",
       "      <th>fulfill_via</th>\n",
       "      <th>vendor_inco_term</th>\n",
       "      <th>shipment_mode</th>\n",
       "      <th>late_delivery</th>\n",
       "      <th>late</th>\n",
       "      <th>product_group</th>\n",
       "      <th>sub_classification</th>\n",
       "      <th>...</th>\n",
       "      <th>line_item_quantity</th>\n",
       "      <th>line_item_value</th>\n",
       "      <th>pack_price</th>\n",
       "      <th>unit_price</th>\n",
       "      <th>manufacturing_site</th>\n",
       "      <th>first_line_designation</th>\n",
       "      <th>weight_kilograms</th>\n",
       "      <th>freight_cost_usd</th>\n",
       "      <th>freight_cost_groups</th>\n",
       "      <th>line_item_insurance_usd</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>36203.0</td>\n",
       "      <td>Nigeria</td>\n",
       "      <td>PMO - US</td>\n",
       "      <td>Direct Drop</td>\n",
       "      <td>EXW</td>\n",
       "      <td>Air</td>\n",
       "      <td>1.0</td>\n",
       "      <td>Yes</td>\n",
       "      <td>HRDT</td>\n",
       "      <td>HIV test</td>\n",
       "      <td>...</td>\n",
       "      <td>2996.0</td>\n",
       "      <td>266644.00</td>\n",
       "      <td>89.00</td>\n",
       "      <td>0.89</td>\n",
       "      <td>Alere Medical Co., Ltd.</td>\n",
       "      <td>Yes</td>\n",
       "      <td>1426.0</td>\n",
       "      <td>33279.83</td>\n",
       "      <td>expensive</td>\n",
       "      <td>373.83</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>30998.0</td>\n",
       "      <td>Botswana</td>\n",
       "      <td>PMO - US</td>\n",
       "      <td>Direct Drop</td>\n",
       "      <td>EXW</td>\n",
       "      <td>Air</td>\n",
       "      <td>0.0</td>\n",
       "      <td>No</td>\n",
       "      <td>HRDT</td>\n",
       "      <td>HIV test</td>\n",
       "      <td>...</td>\n",
       "      <td>25.0</td>\n",
       "      <td>800.00</td>\n",
       "      <td>32.00</td>\n",
       "      <td>1.60</td>\n",
       "      <td>Trinity Biotech, Plc</td>\n",
       "      <td>Yes</td>\n",
       "      <td>10.0</td>\n",
       "      <td>559.89</td>\n",
       "      <td>reasonable</td>\n",
       "      <td>1.72</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>69871.0</td>\n",
       "      <td>Vietnam</td>\n",
       "      <td>PMO - US</td>\n",
       "      <td>Direct Drop</td>\n",
       "      <td>EXW</td>\n",
       "      <td>Air</td>\n",
       "      <td>0.0</td>\n",
       "      <td>No</td>\n",
       "      <td>ARV</td>\n",
       "      <td>Adult</td>\n",
       "      <td>...</td>\n",
       "      <td>22925.0</td>\n",
       "      <td>110040.00</td>\n",
       "      <td>4.80</td>\n",
       "      <td>0.08</td>\n",
       "      <td>Hetero Unit III Hyderabad IN</td>\n",
       "      <td>Yes</td>\n",
       "      <td>3723.0</td>\n",
       "      <td>19056.13</td>\n",
       "      <td>expensive</td>\n",
       "      <td>181.57</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>17648.0</td>\n",
       "      <td>South Africa</td>\n",
       "      <td>PMO - US</td>\n",
       "      <td>Direct Drop</td>\n",
       "      <td>DDP</td>\n",
       "      <td>Ocean</td>\n",
       "      <td>0.0</td>\n",
       "      <td>No</td>\n",
       "      <td>ARV</td>\n",
       "      <td>Adult</td>\n",
       "      <td>...</td>\n",
       "      <td>152535.0</td>\n",
       "      <td>361507.95</td>\n",
       "      <td>2.37</td>\n",
       "      <td>0.04</td>\n",
       "      <td>Aurobindo Unit III, India</td>\n",
       "      <td>Yes</td>\n",
       "      <td>7698.0</td>\n",
       "      <td>11372.23</td>\n",
       "      <td>expensive</td>\n",
       "      <td>779.41</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>5647.0</td>\n",
       "      <td>Uganda</td>\n",
       "      <td>PMO - US</td>\n",
       "      <td>Direct Drop</td>\n",
       "      <td>EXW</td>\n",
       "      <td>Air</td>\n",
       "      <td>0.0</td>\n",
       "      <td>No</td>\n",
       "      <td>HRDT</td>\n",
       "      <td>HIV test - Ancillary</td>\n",
       "      <td>...</td>\n",
       "      <td>850.0</td>\n",
       "      <td>8.50</td>\n",
       "      <td>0.01</td>\n",
       "      <td>0.00</td>\n",
       "      <td>Inverness Japan</td>\n",
       "      <td>Yes</td>\n",
       "      <td>56.0</td>\n",
       "      <td>360.00</td>\n",
       "      <td>reasonable</td>\n",
       "      <td>0.01</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows Ã— 27 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "        id       country managed_by  fulfill_via vendor_inco_term  \\\n",
       "0  36203.0       Nigeria   PMO - US  Direct Drop              EXW   \n",
       "1  30998.0      Botswana   PMO - US  Direct Drop              EXW   \n",
       "2  69871.0       Vietnam   PMO - US  Direct Drop              EXW   \n",
       "3  17648.0  South Africa   PMO - US  Direct Drop              DDP   \n",
       "4   5647.0        Uganda   PMO - US  Direct Drop              EXW   \n",
       "\n",
       "  shipment_mode  late_delivery late product_group    sub_classification  ...  \\\n",
       "0           Air            1.0  Yes          HRDT              HIV test  ...   \n",
       "1           Air            0.0   No          HRDT              HIV test  ...   \n",
       "2           Air            0.0   No           ARV                 Adult  ...   \n",
       "3         Ocean            0.0   No           ARV                 Adult  ...   \n",
       "4           Air            0.0   No          HRDT  HIV test - Ancillary  ...   \n",
       "\n",
       "  line_item_quantity line_item_value pack_price unit_price  \\\n",
       "0             2996.0       266644.00      89.00       0.89   \n",
       "1               25.0          800.00      32.00       1.60   \n",
       "2            22925.0       110040.00       4.80       0.08   \n",
       "3           152535.0       361507.95       2.37       0.04   \n",
       "4              850.0            8.50       0.01       0.00   \n",
       "\n",
       "             manufacturing_site first_line_designation  weight_kilograms  \\\n",
       "0       Alere Medical Co., Ltd.                    Yes            1426.0   \n",
       "1          Trinity Biotech, Plc                    Yes              10.0   \n",
       "2  Hetero Unit III Hyderabad IN                    Yes            3723.0   \n",
       "3     Aurobindo Unit III, India                    Yes            7698.0   \n",
       "4               Inverness Japan                    Yes              56.0   \n",
       "\n",
       "   freight_cost_usd  freight_cost_groups  line_item_insurance_usd  \n",
       "0          33279.83            expensive                   373.83  \n",
       "1            559.89           reasonable                     1.72  \n",
       "2          19056.13            expensive                   181.57  \n",
       "3          11372.23            expensive                   779.41  \n",
       "4            360.00           reasonable                     0.01  \n",
       "\n",
       "[5 rows x 27 columns]"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "late_shipments = feather.read_feather(\"late_shipments.feather\")\n",
    "late_shipments.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Proportions tests\n",
    "\n",
    "## Test for single proportions\n",
    "### Reminder of z-Score use"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Imagine now that we want to calculate the proportion of a certain population, we already did this in the first part of our Hypothesis testing Bible! The steps we took were the following:\n",
    "\n",
    "1. We use the bootstrap distribution to calculate them the standard deviation with NumPy Package.\n",
    "2. We calculate the standardized test statistic, the $\\mathit{z}$-Score.\n",
    "3. With the $\\mathit{z}$-Score, we calculated the $\\mathit{p}$-Value.\n",
    "4. We decide the hypothesis that has more sense.\n",
    "\n",
    "As the bootstrap distribution can be computationally exhausting for the computer, there are other options to do it which can be less tiring for the PC."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "What we used for it was: \n",
    "$$\\mathit{z}-Score = \\frac{\\widehat{p} - \\mathit{p}}{SE(\\widehat{p})}$$\n",
    "\n",
    "If we assume that $H_{0}$ is true, then $\\mathit{p}$ = $\\mathit{p_{0}}$ so:\n",
    "$$\\mathit{z}-Score = \\frac{\\widehat{p} - \\mathit{p_{0}}}{SE(\\widehat{p})}$$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "So knowing the value of $\\mathit{SE}$, that we can look from the previous notebook, we would only need sample information that are $\\widehat{p}$ and $\\mathit{n}$, and the parameter $\\mathit{p_{0}}$ where we decide the hypothesis. Remember that $\\widehat{p}$ is the sample proportion from the population, and n the number of samples.\n",
    "\n",
    "### Why do we use z instead of t?\n",
    "\n",
    "Remember that $\\mathit{t}$ is calculated, for example in the german and belgian beers case as:\n",
    "\n",
    "$$\\mathit{t} = \\frac{(\\mu_{German} - \\mu_{Belgian})}{\\sqrt{\\frac{\\mathit{s}^{2}_{German}}{n_{German}} + \\frac{\\mathit{s}^{2}_{Belgian}}{n_{Belgian}}}}$$\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This means that the numerator estimates the deviation of the mean, and s, that is for standard deviation, estimates the population standard deviation...**But it is calculated from $\\mu$! If we combine then that increases the uncertainty of the model.**\n",
    "\n",
    "This is more ovious when we remember that the tails in $\\mathit{t}$-tests are fatter, so we wold reject wrongly the null hypothesis. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We are going to do the same test but with $\\mathit{p}$-Value with an $\\alpha$ = 0.05."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- Our hypothesis is that 6% of shipments are late, and we calculate the value as *\"p-hat\"*."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Hypothesize that the proportion of late shipments is 6%\n",
    "p_0 = 0.06\n",
    "p_hat = (late_shipments['late'] == \"Yes\").mean()\n",
    "n = len(late_shipments)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "And then we calculate the numerator and denominator to obtain the $\\mathit{z}$-Score and with it, the $\\mathit{p}$-Value."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.44703503936503364"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# z-Score\n",
    "numerator = p_hat - p_0\n",
    "denominator = np.sqrt(p_0 * (1 - p_0)/ n)\n",
    "z_score = numerator / denominator\n",
    "\n",
    "# REMINDER:\n",
    "#- Our null hypothesis is that **the proportion of late shipments is 6%**\n",
    "#- Our alternative hypothesis is that **the proportion of late shipments is more than 6%**\n",
    "p_value = 1 - norm.cdf(z_score)\n",
    "p_value"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "So we fail to reject $H_{0}$ and we have found an easier path for one sample proportion test."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "------------------------"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Two-sample proportions tests\n",
    "### A nightmare at first-sight"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In case we are comparing a two sample proportion tests, we would be comparing two proportions that would have a much more complex mathematical form. \n",
    "\n",
    "**We would need the double of arguments than the one-sample proportion tests** as we have now two different populations with different proportions. \n",
    "\n",
    "**Notice that in the previous example, we were saying a fact of the proportion, while in this case, we are comparing proportions!**\n",
    "\n",
    "We would have something similar to the case that we were comparing means. For example we can say that:\n",
    "\n",
    "- $H_{0}$: Proportion of smokers is the same under 30 as those at least thirty\n",
    "- $H_{A}$: Proportion of smokers is different under 30 than those at least thirty\n",
    "\n",
    "Now, our $\\mathit{z}$-Score equation would be:\n",
    "\n",
    "$$\\mathit{z}-Score = \\frac{(\\widehat{p}_{\\geq 30} - \\widehat{p}_{< 30}) - 0}{SE(\\widehat{p}_{\\geq 30} - \\widehat{p}_{<30})}$$\n",
    "\n",
    "And the Standard Error now is again a combination of both, which is:\n",
    "\n",
    "$$SE(\\widehat{p}_{\\geq 30} - \\widehat{p}_{<30}) = \\sqrt{\\frac{\\widehat{p}(1- \\widehat{p})}{n_{\\geq 30}} + \\frac{\\widehat{p}(1- \\widehat{p})}{n_{< 30}}}$$\n",
    "\n",
    "But, look at this! Now the value of $\\widehat{p}$ is **a ponderated version of both groups**. Things are getting messy:\n",
    "\n",
    "$$\\widehat{p} = \\frac{n_{\\geq 30} \\times \\widehat{p}_{\\geq{30}} + n_{<30} \\times \\widehat{p}_{<{30}}}{n_{\\geq 30} \\times n_{< 30}}$$\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### How do we solve this nightmare?\n",
    "\n",
    "Obviously this is a simple guide. And that is not simple. So we extract these conclusions:\n",
    "\n",
    "1. You only need 4 variables: $n_{\\geq 30}$ , $\\widehat{p}_{\\geq{30}}$ , $n_{<30}$ and $\\widehat{p}_{<{30}}$ to solve the hypothesis test.\n",
    "2. You only need **pandas** to calculate them!\n",
    "\n",
    "### Normal solving method\n",
    "\n",
    "In our example, we are going to do the following two-sample proportion test:\n",
    "\n",
    "- $H_{0}$: The shipments where the amount paid for freight have the same proportion of lateness as the ones that the amount paid for freight is reasonable.\n",
    "\n",
    "$$late_{expensive} - late_{reasonable} = 0$$\n",
    "- $H_{A}$: The shipments where the amount paid for freight have a bigger proportion of late shipments than the ones that the amount paid for freight is reasonable.\n",
    "$$late_{expensive} - late_{reasonable} > 0$$\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(freight_cost_groups  late\n",
       " expensive            No      0.920904\n",
       "                      Yes     0.079096\n",
       " reasonable           No      0.964835\n",
       "                      Yes     0.035165\n",
       " Name: proportion, dtype: float64,\n",
       " freight_cost_groups\n",
       " expensive     531\n",
       " reasonable    455\n",
       " Name: late, dtype: int64)"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "p_hats = late_shipments.groupby(\"freight_cost_groups\")[\"late\"].value_counts(normalize = True)\n",
    "ns = late_shipments.groupby(\"freight_cost_groups\")[\"late\"].count()\n",
    "p_hats, ns"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We calculate now the 4 variables:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.0017353400023595311"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Calculate the pooled estimate of the population proportion\n",
    "p_hat = (p_hats[\"reasonable\"] * ns[\"reasonable\"] + p_hats[\"expensive\"] * ns[\"expensive\"]) \\\n",
    "                    / (ns[\"reasonable\"] + ns[\"expensive\"]) #denominator\n",
    "\n",
    "p_hat_times_not_p_hat = p_hat * (1 - p_hat)\n",
    "p_hat_times_not_p_hat_over_ns = p_hat_times_not_p_hat / ns[\"expensive\"] + p_hat_times_not_p_hat / ns[\"reasonable\"]\n",
    "std_error = np.sqrt(p_hat_times_not_p_hat_over_ns)[\"Yes\"]\n",
    "\n",
    "# Calculate the z-score\n",
    "z_score = ((p_hats[\"expensive\"] - p_hats[\"reasonable\"]) / std_error)[\"Yes\"]\n",
    "\n",
    "# p-value from the z-score RIGHT TAILED\n",
    "p_value = (1 - norm.cdf(z_score))\n",
    "p_value"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Proportions z-test: The fast-way"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Another way to do the exact same operation but without arithetic. You do not have to do much calculus and just knowing whatÂ´s going on behind is ok to understand and obtain coherent results:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(2.922648567784529, 0.001735340002359578)"
      ]
     },
     "execution_count": 40,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "late_by_freight_cost_group = late_shipments.groupby(\"freight_cost_groups\")[\"late\"].value_counts()\n",
    "\n",
    "#Are they expensive? Yes, so we pick that rows\n",
    "success_counts = np.array([late_by_freight_cost_group[(\"expensive\",\"Yes\")], late_by_freight_cost_group[(\"reasonable\",\"Yes\")]])\n",
    "\n",
    "# Number of elements\n",
    "n = np.array([late_by_freight_cost_group[\"expensive\"].values.sum(), late_by_freight_cost_group[\"reasonable\"].values.sum()])\n",
    "\n",
    "# z-test\n",
    "z_score, p_value = proportions_ztest(count = success_counts, nobs = n, alternative = \"larger\")\n",
    "z_score, p_value"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "ThatÂ´s how we simplify that equation with **statsmodels**!\n",
    "In case you do not have the package, you can use the link to download it:\n",
    "\n",
    "https://www.statsmodels.org/stable/index.html"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "-------------------"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
