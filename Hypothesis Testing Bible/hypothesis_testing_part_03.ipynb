{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In this Notebook I will continue the **Hypothesis tests** main tests to clarify the difficulties while trying to understand this statistical concept. This is the second part of my series *\"The Hypothesis-Testing Bible\"*. If you want to know further about the dataset or more elemental concepts, please check the first part on my GitHub repository. Link below.\n",
    "\n",
    "https://github.com/Seniorveiga/Python_Projects/tree/main/Hypothesis%20Testing%20Bible\n",
    "\n",
    "In this notebook we will have a walk over more complex tests. They will be:\n",
    "\n",
    "## Index\n",
    "\n",
    "- Non-parametric tests\n",
    "    - Wilcoxon tests\n",
    "    - Wilcoxon-Man-Whotney tests\n",
    "    - Kruskal-Wallis tests"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "--------------------"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Packages and dataset import"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Again, we import the package so that it appears again to do our operations and the hypothesis tests.\n",
    "Nevertheless, we are going to introduce another dataset based on the first part that is the *\"repub_votes_potus_08_12\"* which do not follow the conditions to apply a parametric test."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\Manu\\AppData\\Local\\anaconda3\\Lib\\site-packages\\pandas\\core\\arrays\\masked.py:60: UserWarning: Pandas requires version '1.3.6' or newer of 'bottleneck' (version '1.3.5' currently installed).\n",
      "  from pandas.core import (\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import pyarrow.feather as feather\n",
    "import numpy as np \n",
    "from scipy.stats import norm, t, chi2, chisquare\n",
    "import matplotlib.pyplot as plt\n",
    "import pingouin\n",
    "import seaborn as sns\n",
    "from statsmodels.stats.proportion import proportions_ztest"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>country</th>\n",
       "      <th>managed_by</th>\n",
       "      <th>fulfill_via</th>\n",
       "      <th>vendor_inco_term</th>\n",
       "      <th>shipment_mode</th>\n",
       "      <th>late_delivery</th>\n",
       "      <th>late</th>\n",
       "      <th>product_group</th>\n",
       "      <th>sub_classification</th>\n",
       "      <th>...</th>\n",
       "      <th>line_item_quantity</th>\n",
       "      <th>line_item_value</th>\n",
       "      <th>pack_price</th>\n",
       "      <th>unit_price</th>\n",
       "      <th>manufacturing_site</th>\n",
       "      <th>first_line_designation</th>\n",
       "      <th>weight_kilograms</th>\n",
       "      <th>freight_cost_usd</th>\n",
       "      <th>freight_cost_groups</th>\n",
       "      <th>line_item_insurance_usd</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>36203.0</td>\n",
       "      <td>Nigeria</td>\n",
       "      <td>PMO - US</td>\n",
       "      <td>Direct Drop</td>\n",
       "      <td>EXW</td>\n",
       "      <td>Air</td>\n",
       "      <td>1.0</td>\n",
       "      <td>Yes</td>\n",
       "      <td>HRDT</td>\n",
       "      <td>HIV test</td>\n",
       "      <td>...</td>\n",
       "      <td>2996.0</td>\n",
       "      <td>266644.00</td>\n",
       "      <td>89.00</td>\n",
       "      <td>0.89</td>\n",
       "      <td>Alere Medical Co., Ltd.</td>\n",
       "      <td>Yes</td>\n",
       "      <td>1426.0</td>\n",
       "      <td>33279.83</td>\n",
       "      <td>expensive</td>\n",
       "      <td>373.83</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>30998.0</td>\n",
       "      <td>Botswana</td>\n",
       "      <td>PMO - US</td>\n",
       "      <td>Direct Drop</td>\n",
       "      <td>EXW</td>\n",
       "      <td>Air</td>\n",
       "      <td>0.0</td>\n",
       "      <td>No</td>\n",
       "      <td>HRDT</td>\n",
       "      <td>HIV test</td>\n",
       "      <td>...</td>\n",
       "      <td>25.0</td>\n",
       "      <td>800.00</td>\n",
       "      <td>32.00</td>\n",
       "      <td>1.60</td>\n",
       "      <td>Trinity Biotech, Plc</td>\n",
       "      <td>Yes</td>\n",
       "      <td>10.0</td>\n",
       "      <td>559.89</td>\n",
       "      <td>reasonable</td>\n",
       "      <td>1.72</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>69871.0</td>\n",
       "      <td>Vietnam</td>\n",
       "      <td>PMO - US</td>\n",
       "      <td>Direct Drop</td>\n",
       "      <td>EXW</td>\n",
       "      <td>Air</td>\n",
       "      <td>0.0</td>\n",
       "      <td>No</td>\n",
       "      <td>ARV</td>\n",
       "      <td>Adult</td>\n",
       "      <td>...</td>\n",
       "      <td>22925.0</td>\n",
       "      <td>110040.00</td>\n",
       "      <td>4.80</td>\n",
       "      <td>0.08</td>\n",
       "      <td>Hetero Unit III Hyderabad IN</td>\n",
       "      <td>Yes</td>\n",
       "      <td>3723.0</td>\n",
       "      <td>19056.13</td>\n",
       "      <td>expensive</td>\n",
       "      <td>181.57</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>17648.0</td>\n",
       "      <td>South Africa</td>\n",
       "      <td>PMO - US</td>\n",
       "      <td>Direct Drop</td>\n",
       "      <td>DDP</td>\n",
       "      <td>Ocean</td>\n",
       "      <td>0.0</td>\n",
       "      <td>No</td>\n",
       "      <td>ARV</td>\n",
       "      <td>Adult</td>\n",
       "      <td>...</td>\n",
       "      <td>152535.0</td>\n",
       "      <td>361507.95</td>\n",
       "      <td>2.37</td>\n",
       "      <td>0.04</td>\n",
       "      <td>Aurobindo Unit III, India</td>\n",
       "      <td>Yes</td>\n",
       "      <td>7698.0</td>\n",
       "      <td>11372.23</td>\n",
       "      <td>expensive</td>\n",
       "      <td>779.41</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>5647.0</td>\n",
       "      <td>Uganda</td>\n",
       "      <td>PMO - US</td>\n",
       "      <td>Direct Drop</td>\n",
       "      <td>EXW</td>\n",
       "      <td>Air</td>\n",
       "      <td>0.0</td>\n",
       "      <td>No</td>\n",
       "      <td>HRDT</td>\n",
       "      <td>HIV test - Ancillary</td>\n",
       "      <td>...</td>\n",
       "      <td>850.0</td>\n",
       "      <td>8.50</td>\n",
       "      <td>0.01</td>\n",
       "      <td>0.00</td>\n",
       "      <td>Inverness Japan</td>\n",
       "      <td>Yes</td>\n",
       "      <td>56.0</td>\n",
       "      <td>360.00</td>\n",
       "      <td>reasonable</td>\n",
       "      <td>0.01</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 27 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "        id       country managed_by  fulfill_via vendor_inco_term  \\\n",
       "0  36203.0       Nigeria   PMO - US  Direct Drop              EXW   \n",
       "1  30998.0      Botswana   PMO - US  Direct Drop              EXW   \n",
       "2  69871.0       Vietnam   PMO - US  Direct Drop              EXW   \n",
       "3  17648.0  South Africa   PMO - US  Direct Drop              DDP   \n",
       "4   5647.0        Uganda   PMO - US  Direct Drop              EXW   \n",
       "\n",
       "  shipment_mode  late_delivery late product_group    sub_classification  ...  \\\n",
       "0           Air            1.0  Yes          HRDT              HIV test  ...   \n",
       "1           Air            0.0   No          HRDT              HIV test  ...   \n",
       "2           Air            0.0   No           ARV                 Adult  ...   \n",
       "3         Ocean            0.0   No           ARV                 Adult  ...   \n",
       "4           Air            0.0   No          HRDT  HIV test - Ancillary  ...   \n",
       "\n",
       "  line_item_quantity line_item_value pack_price unit_price  \\\n",
       "0             2996.0       266644.00      89.00       0.89   \n",
       "1               25.0          800.00      32.00       1.60   \n",
       "2            22925.0       110040.00       4.80       0.08   \n",
       "3           152535.0       361507.95       2.37       0.04   \n",
       "4              850.0            8.50       0.01       0.00   \n",
       "\n",
       "             manufacturing_site first_line_designation  weight_kilograms  \\\n",
       "0       Alere Medical Co., Ltd.                    Yes            1426.0   \n",
       "1          Trinity Biotech, Plc                    Yes              10.0   \n",
       "2  Hetero Unit III Hyderabad IN                    Yes            3723.0   \n",
       "3     Aurobindo Unit III, India                    Yes            7698.0   \n",
       "4               Inverness Japan                    Yes              56.0   \n",
       "\n",
       "   freight_cost_usd  freight_cost_groups  line_item_insurance_usd  \n",
       "0          33279.83            expensive                   373.83  \n",
       "1            559.89           reasonable                     1.72  \n",
       "2          19056.13            expensive                   181.57  \n",
       "3          11372.23            expensive                   779.41  \n",
       "4            360.00           reasonable                     0.01  \n",
       "\n",
       "[5 rows x 27 columns]"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "late_shipments = feather.read_feather(\"late_shipments.feather\")\n",
    "late_shipments.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>state</th>\n",
       "      <th>county</th>\n",
       "      <th>dem_percent_12</th>\n",
       "      <th>dem_percent_16</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Alabama</td>\n",
       "      <td>Bullock</td>\n",
       "      <td>76.305900</td>\n",
       "      <td>74.946921</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Alabama</td>\n",
       "      <td>Chilton</td>\n",
       "      <td>19.453671</td>\n",
       "      <td>15.847352</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Alabama</td>\n",
       "      <td>Clay</td>\n",
       "      <td>26.673672</td>\n",
       "      <td>18.674517</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Alabama</td>\n",
       "      <td>Cullman</td>\n",
       "      <td>14.661752</td>\n",
       "      <td>10.028252</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Alabama</td>\n",
       "      <td>Escambia</td>\n",
       "      <td>36.915731</td>\n",
       "      <td>31.020546</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "     state    county  dem_percent_12  dem_percent_16\n",
       "0  Alabama   Bullock       76.305900       74.946921\n",
       "1  Alabama   Chilton       19.453671       15.847352\n",
       "2  Alabama      Clay       26.673672       18.674517\n",
       "3  Alabama   Cullman       14.661752       10.028252\n",
       "4  Alabama  Escambia       36.915731       31.020546"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sample_dem_data = feather.read_feather(\"dem_votes_potus_12_16.feather\")\n",
    "sample_dem_data.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Non-parametric test\n",
    "\n",
    "There are certain asumptions that we do on our population that makes us use usual parametric tests.\n",
    "\n",
    "### Parameters\n",
    "#### Randomness\n",
    "All hypothesis tests assume that they belong to a random sample. In case we don´t confirm this hypothesis we cannot say that the sample is representative of the population. This should be reconsidered through the collection method of the data.\n",
    "\n",
    "We would need to ask to the source of the data to know the origin.\n",
    "\n",
    "#### Independence of observations\n",
    "We assume that each row is independent. If we don´t consider the dependencies we would have more false positive / false negatives in our tests. Again, it should be checked in the collection method.\n",
    "\n",
    "#### Large sample size\n",
    "If the sample is big enough we can apply the central limit theorem, this is that data can be paired with a normal distribution.\n",
    "If it is not applied what happens is that the tests that we perform on our data cannot conclude anything solid so it would again return lots of false positives and negatives.\n",
    "\n",
    "#### Solutions\n",
    "\n",
    "- As a general rule, we need **at least 30 observations** in our samples, unless we do it with two samples, that we wold need 30 in each one.\n",
    "- In case of proportion tests:\n",
    "    - If we do it with one sample, there should be **at least 10 failures and 10 successes**.\n",
    "    - If we do it with two samples, there should be **at least 10 failures and 10 successes in each samples**.\n",
    "\n",
    "![](https://unicornlifescience.com/wp-content/uploads/2022/03/biological-samples.jpg)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let´s see an example in our dataset, *\"late_shipments\"*:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "vendor_inco_term  freight_cost_groups\n",
       "CIP               reasonable              34\n",
       "                  expensive               16\n",
       "DDP               expensive               55\n",
       "                  reasonable              45\n",
       "DDU               reasonable               1\n",
       "EXW               expensive              423\n",
       "                  reasonable             302\n",
       "FCA               reasonable              73\n",
       "                  expensive               37\n",
       "Name: count, dtype: int64"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "counts = late_shipments.groupby(\"vendor_inco_term\")[\"freight_cost_groups\"].value_counts()\n",
    "counts"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "As we see, in this group we did not include DDU in our analysis so we cannot rely on the results obtained from DDU."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Nevertheless, when we see the *\"shipment mode\"* group:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "shipment_mode\n",
       "Air            906\n",
       "Ocean           88\n",
       "Air Charter      6\n",
       "Name: count, dtype: int64"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "counts = late_shipments[\"shipment_mode\"].value_counts()\n",
    "# Inspect whether the counts are big enough\n",
    "counts"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We see that **we cannot rely on the results of an ANOVA test for the comparisons with Air Charter** due to the lack of samples."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "-------------------------"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### What´s a non-parametric test?\n",
    "\n",
    "We have already seen ther types of tests that are the $\\mathit{z}$-proportions, the $\\mathit{t}$-tests or the ANOVA, but what is exactly a non-parametric test?\n",
    "\n",
    "A **non-parametric test** is a type of test that we do when the sample that we are working with do not follow the rules established above, such as verifying the central limit theorem or do not have enough samples. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "For examples, if we pick 5 different rows from the *\"dem_votes_potus_12_16\"* and we perform a $\\mathit{t}$-test:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>state</th>\n",
       "      <th>county</th>\n",
       "      <th>dem_percent_12</th>\n",
       "      <th>dem_percent_16</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>416</th>\n",
       "      <td>Texas</td>\n",
       "      <td>Gonzales</td>\n",
       "      <td>29.337956</td>\n",
       "      <td>24.802652</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>192</th>\n",
       "      <td>Massachusetts</td>\n",
       "      <td>Essex</td>\n",
       "      <td>57.403571</td>\n",
       "      <td>58.522961</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>Arkansas</td>\n",
       "      <td>Dallas</td>\n",
       "      <td>43.352789</td>\n",
       "      <td>42.042584</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>287</th>\n",
       "      <td>New Jersey</td>\n",
       "      <td>Sussex</td>\n",
       "      <td>38.426096</td>\n",
       "      <td>32.663303</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>338</th>\n",
       "      <td>Ohio</td>\n",
       "      <td>Harrison</td>\n",
       "      <td>41.310741</td>\n",
       "      <td>23.845176</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>160</th>\n",
       "      <td>Kentucky</td>\n",
       "      <td>Boyle</td>\n",
       "      <td>36.135133</td>\n",
       "      <td>33.068129</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>274</th>\n",
       "      <td>Nebraska</td>\n",
       "      <td>Perkins</td>\n",
       "      <td>17.073171</td>\n",
       "      <td>11.065292</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>185</th>\n",
       "      <td>Maine</td>\n",
       "      <td>Lincoln</td>\n",
       "      <td>54.511731</td>\n",
       "      <td>47.625913</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>339</th>\n",
       "      <td>Ohio</td>\n",
       "      <td>Hocking</td>\n",
       "      <td>48.373664</td>\n",
       "      <td>29.404892</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>126</th>\n",
       "      <td>Iowa</td>\n",
       "      <td>Chickasaw</td>\n",
       "      <td>54.811845</td>\n",
       "      <td>35.213675</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "             state     county  dem_percent_12  dem_percent_16\n",
       "416          Texas   Gonzales       29.337956       24.802652\n",
       "192  Massachusetts      Essex       57.403571       58.522961\n",
       "19        Arkansas     Dallas       43.352789       42.042584\n",
       "287     New Jersey     Sussex       38.426096       32.663303\n",
       "338           Ohio   Harrison       41.310741       23.845176\n",
       "160       Kentucky      Boyle       36.135133       33.068129\n",
       "274       Nebraska    Perkins       17.073171       11.065292\n",
       "185          Maine    Lincoln       54.511731       47.625913\n",
       "339           Ohio    Hocking       48.373664       29.404892\n",
       "126           Iowa  Chickasaw       54.811845       35.213675"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Picking a sample of n=5\n",
    "small_sample = sample_dem_data.sample(n=5)\n",
    "small_sample"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "- $H_{0}$: The proportion of democratic votes in 2012 and 2016 were the same. \n",
    "- $H_{A}$: The proportion of democratic votes in 2012 was bigger than 2016.\n",
    "Significance level: 0.01"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>T</th>\n",
       "      <th>dof</th>\n",
       "      <th>alternative</th>\n",
       "      <th>p-val</th>\n",
       "      <th>CI95%</th>\n",
       "      <th>cohen-d</th>\n",
       "      <th>BF10</th>\n",
       "      <th>power</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>T-test</th>\n",
       "      <td>30.298384</td>\n",
       "      <td>499</td>\n",
       "      <td>greater</td>\n",
       "      <td>1.800317e-115</td>\n",
       "      <td>[6.46, inf]</td>\n",
       "      <td>0.454202</td>\n",
       "      <td>4.491e+111</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                T  dof alternative          p-val        CI95%   cohen-d  \\\n",
       "T-test  30.298384  499     greater  1.800317e-115  [6.46, inf]  0.454202   \n",
       "\n",
       "              BF10  power  \n",
       "T-test  4.491e+111    1.0  "
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Perform a t-test\n",
    "paired_test_results = pingouin.ttest(x=sample_dem_data['dem_percent_12'], \n",
    "                                     y=sample_dem_data['dem_percent_16'],\n",
    "                                     paired=True,\n",
    "                                     alternative=\"greater\")\n",
    "\n",
    "paired_test_results"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "But, is this reliable? "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "-------------"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Non-parametric non-liar"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Non-parametric tests helps us to have a reliable source while performing tests on our population.\n",
    "The first one that was non-parametric was caled the **Wilcoxon tests**, that we can use by:\n",
    "\n",
    "1. Taking the differences between the columns that we want to compare \n",
    "2. Take the absolute value of them.\n",
    "3. After that, we rank the data with the *scipy.stats* function called *rankdata*.\n",
    "\n",
    "The last part is to calcualte W, which is a test that we make with 2 variables:\n",
    "- Adding the values by ranking values which difference is negative in a variable called $\\mathit{T}^{-}$\n",
    "- Adding the values by ranking values which difference is positive in a variable called $\\mathit{T}^{+}$\n",
    "\n",
    "We can do this directly with **pingouin.wilcoxon**.\n",
    "\n",
    "Let´s see it!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "             W-val alternative         p-val       RBC      CLES\n",
      "Wilcoxon  122849.0     greater  8.901980e-78  0.961661  0.644816\n"
     ]
    }
   ],
   "source": [
    "wilcoxon_test_results = pingouin.wilcoxon( x = sample_dem_data[\"dem_percent_12\"],\\\n",
    "                                           y = sample_dem_data[\"dem_percent_16\"], alternative = \"greater\")\n",
    "\n",
    "# Print Wilcoxon test results\n",
    "print(wilcoxon_test_results)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "It was reliable! That´s due to the little amount of values that we had that the $\\mathit{t}$-test was less restrictive so in smaller populations we should use this one!"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "------------------------------"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Wilcoxon-Mann-Whitney\n",
    "\n",
    "We are going to see other non-parametric, but rather than being paired numeric statistics, they are non-paired satistics. \n",
    "The Wilcoxon-Mann-Whitney does exactly that but works on unpaired data. \n",
    "\n",
    "To do it, we need to put the data in wide-format, which we can do by using the function .pivot(). \n",
    "\n",
    "It wll be displayed as two columns where there are values and NaN´s that belong to the other column which has value. Remember that the last test **was not** a Wilcoxon Mann Whitney due to the sample of origin: If they were different people voting they will be diferent.\n",
    "\n",
    "### Kruskal-Wallis\n",
    "\n",
    "This is exactly the same as the ANOVA function but it serves as the non-parametric version.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>U-val</th>\n",
       "      <th>alternative</th>\n",
       "      <th>p-val</th>\n",
       "      <th>RBC</th>\n",
       "      <th>CLES</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>MWU</th>\n",
       "      <td>19134.0</td>\n",
       "      <td>two-sided</td>\n",
       "      <td>0.000014</td>\n",
       "      <td>0.331902</td>\n",
       "      <td>0.334049</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "       U-val alternative     p-val       RBC      CLES\n",
       "MWU  19134.0   two-sided  0.000014  0.331902  0.334049"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# You need to pick the column for unpaired data\n",
    "weight_vs_late = late_shipments[[\"weight_kilograms\",\"late\"]]\n",
    "\n",
    "# Convert weight_vs_late into wide format\n",
    "weight_vs_late_wide = weight_vs_late.pivot(columns='late', \n",
    "                                           values=\"weight_kilograms\")\n",
    "\n",
    "# two-sided Wilcoxon-Mann-Whitney test\n",
    "wmw_test = pingouin.mwu(x = weight_vs_late_wide[\"No\"],y = weight_vs_late_wide[\"Yes\"])\n",
    "wmw_test"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The small p-value here leads us to suspect that a difference does exist in the weight of the shipment and whether or not it was late. The Wilcoxon-Mann-Whitney test is useful when you cannot satisfy the assumptions for a parametric test comparing two means, like the t-test.\n",
    "\n",
    "For the Kruskal-Wallis:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Kruskal-Wallis test on weight_kilograms vs. shipment_mode\n",
    "kw_test = pingouin.kruskal(data = late_shipments, dv = \"weight_kilograms\", between = \"shipment_mode\")\n",
    "kw_test"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The Kruskal-Wallis test returned a very small p-value, so there is evidence that at least one of the three groups of shipment mode has a different weight distribution than the others. Th Kruskal-Wallis test is comparable to an ANOVA, which tests for a difference in means across multiple groups."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "-----"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
